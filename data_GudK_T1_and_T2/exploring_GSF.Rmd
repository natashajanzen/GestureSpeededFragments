---
title: "Exploring the GSF data"
output:
  html_document:
    toc: TRUE
    toc_float: TRUE
    df_print: "paged"
---

```{r, message = FALSE}
library(dplyr)
library(ggplot2)
library(readr)
library(stringr)
library(tidyr)
```

```{r}
d <- read_csv("GudK_T1_and_T2_fixed.csv")
```

```{r}
d
```

## Overview

We want to know about correctness and speed of responses. The main predictor is the `condition` variable. Here are a few plots.

### Proportion correct by condition

```{r, fig.width = 9, fig.height = 6}
d %>%
  ggplot(aes(x = condition, fill = correct)) +
  geom_bar(position = position_dodge()) +
  facet_wrap(vars(subject)) ->
  fig_responses

fig_responses
```

Most subjects did quite well. But **EB12AY**, **ED21AD**, and **HA28TH** got nearly half their answers wrong. It doesn't look as though one condition was consistently more difficult than the other.

### RT distributions by condition

Considering only correct responses.

I always have to google how to show distributions overlaid on each other with ggplot, despite having done it enough times. It's the use of `position_identity()` that trips me up. This prevents the default positioning of bars stacked on top of each other instead of overlaid.

I've applied an arbitrary RT cutoff to stop the horizontal scale from getting too stretched out.

```{r, fig.width = 9, fig.height = 6}
d %>%
  filter(correct, RT < 5) %>%
  ggplot(aes(x = RT, y = after_stat(density), fill = condition)) +
  geom_histogram(
    position = position_identity(),
    alpha = 0.4,
    binwidth = 0.1
  ) +
  facet_wrap(vars(subject)) +
  labs(x = "RT (s)") ->
  fig_RT

fig_RT
```

Most look like classic RT distributions, with an early peak and a long tail. A few subjects seem to be more uniformly taking their time. Most of these are the same ones that got nearly half their answers wrong.

### Mean RT by condition and correctness

The full distributions might be masking subtle on-average differences. So we can look at a plot of means as well.

Varying the vertical axis scale by subject (with `scales = "free_y"`) gives a closer view of each subject's pattern.

Since a plot of means is less cluttered than a full histogram, we can bring back the incorrect responses just in case those are of interest.

```{r, fig.width = 9, fig.height = 6, message = FALSE}
d %>%
  ggplot(aes(x = condition, y = RT, color = correct)) +
  stat_summary(
    position = position_dodge(width = 0.2),
    fun.data = mean_sdl,
    fun.args = c(mult = 1)
  ) +
  facet_wrap(vars(subject), scales = "free_y") +
  labs(y = "mean RT (s)", caption = "mean Â±1 SD") ->
  fig_mean_RT

fig_mean_RT
```

Subjects tend to be faster with correct responses. Makes sense. There doesn't seem to be a consistent difference between conditions.

## Session effects

Do subjects get quicker at the task from one session to the next?

```{r, fig.width = 9, fig.height = 6}
(fig_mean_RT %+% filter(d, correct)) +
  aes(x = as.character(session), color = condition) +
  labs(x = "session") ->
  fig_session

fig_session
```

Not consistently.

## Hand words

Curiously, there isn't actually a variable recording the correct word for each trial. This is my omission, something I forgot in the Python program for the experiment. But we can piece the words together from the gap text variable (e.g. *n_se*) and the correct letter variable (e.g. *o*).

```{r}
d %>%
  mutate(full_answer = str_replace(target, "_", corrAns)) ->
  d

d %>%
  select(full_answer) %>%
  distinct()
```

Now we can mark the hand-related words with a new variable. We have a separate data file that assigns categories to the words according to some scheme somebody came up with.

```{r}
handfulness <- read_csv("handAssociation.csv")
```

```{r}
handfulness
```

We join this to the main data frame.

```{r}
d %>%
  left_join(handfulness, by = "full_answer") ->
  d

head(d)
```

One thing to watch out for when we use the new variable is that many values are `NA`. This is because the handfulness data file only lists the verbs. The non-verb words have no handfulness value.

Now we can see the same figure of mean reaction times as above, but with the hand word variable in place of condition.

```{r, fig.width = 9, fig.height = 6}
d %>%
  drop_na(hand_association) ->
  d_hands

(fig_mean_RT %+% d_hands) +
  aes(x = hand_association) +
  labs(x = "word type") ->
  fig_mean_RT_hands

fig_mean_RT_hands
```

No striking pattern. But there probably aren't enough of each kind of hand word to go on.

We are also interested in reproducing approximately the figure on page 5 of [this article](https://doi.org/10.1016/j.neuropsychologia.2020.107563). This has box-and-dotplots (or whatever you call those) of mean RT for the three handfulness categories, with the overall mean and standard error for each.

```{r}
d_hands %>%
  group_by(subject, full_answer, hand_association) %>%
  summarize(mean_RT = mean(RT), .groups = "drop") ->
  d_hands_means

d_hands_means %>%
  ggplot(aes(x = hand_association, y = mean_RT)) +
  geom_boxplot(outlier.shape = "") +
  geom_point(
    position = position_jitter(width = 0.2, height = 0),
    shape = "circle filled",
    fill = "grey"
  ) +
  stat_summary(fun.data = mean_se) +
  labs(x = "word type", y = "mean RT (s)") ->
  fig_Kogan

fig_Kogan
```

And also comparing only MAVs (Manual Action Verbs) to the other verbs.

```{r}
d_hands %>%
  mutate(MAV = hand_association == "MaV") %>%
  group_by(subject, full_answer, MAV) %>%
  summarize(mean_RT = mean(RT), .groups = "drop") ->
  d_hands_means_MAV

(fig_Kogan %+% d_hands_means_MAV) +
  aes(x = MAV)
```

## RT cutoff

The solution you linked on [StackOverflow](https://stackoverflow.com/questions/61601426/remove-outlier-rows-by-column-and-factor-in-r) looks good, and I think you are close to making it work for your case. But this sort of thing can be done much more clearly using the `dplyr` package. Also, using column numbers instead of names is always a bit risky.

The first tricky part of the problem is that we need a separate mean and standard deviation per subject. We can solve this with `group_by()` and then `summarize()`.

```{r}
d %>%
  filter(correct) %>%
  group_by(subject) %>%
  summarize(.groups = "drop",
    RT_mean = mean(RT),
    RT_SD = sd(RT)
  ) ->
  subject_summaries
```

Then use the new variables to calculate a cutoff per subject.

```{r}
RT_SD_multiplier <- 2.5

subject_summaries %>%
  mutate(RT_cutoff = RT_mean + RT_SD_multiplier * RT_SD) ->
  subject_summaries

subject_summaries
```

Let's check with a plot. We can add the cutoffs to the plot of RT distributions from earlier.

```{r, fig.width = 9, fig.height = 6}
fig_RT +
  geom_vline(
    mapping = aes(xintercept = RT_cutoff),
    data = subject_summaries,
    linetype = "dashed"
  )
```

Now we can join this information back into the main data frame.

```{r}
d %>%
  left_join(subject_summaries) ->
  d
```

And use it with `filter()` in subsequent plots or analyses.

```{r}
d %>%
  filter(RT < RT_cutoff)
```
